{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4218701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanyan/dev/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2485063603769504, tolerance: 0.1347958848368591\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/hanyan/dev/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9525783038131976, tolerance: 0.1347958848368591\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/hanyan/dev/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.155918541512847, tolerance: 0.1347958848368591\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/hanyan/dev/.venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.900113230474062, tolerance: 0.1347958848368591\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/home/hanyan/dev/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.0517 - mae: 0.8893 - val_loss: 1.0119 - val_mae: 0.8441\n",
      "Epoch 2/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9784 - mae: 0.8511 - val_loss: 1.0012 - val_mae: 0.8423\n",
      "Epoch 3/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0090 - mae: 0.8732 - val_loss: 1.0036 - val_mae: 0.8460\n",
      "Epoch 4/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9727 - mae: 0.8580 - val_loss: 1.0020 - val_mae: 0.8417\n",
      "Epoch 5/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9348 - mae: 0.8379 - val_loss: 0.9980 - val_mae: 0.8407\n",
      "Epoch 6/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9729 - mae: 0.8595 - val_loss: 0.9982 - val_mae: 0.8434\n",
      "Epoch 7/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9398 - mae: 0.8455 - val_loss: 0.9938 - val_mae: 0.8399\n",
      "Epoch 8/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8948 - mae: 0.8236 - val_loss: 1.0024 - val_mae: 0.8422\n",
      "Epoch 9/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8693 - mae: 0.8033 - val_loss: 1.0085 - val_mae: 0.8436\n",
      "Epoch 10/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8776 - mae: 0.8177 - val_loss: 1.0064 - val_mae: 0.8392\n",
      "Epoch 11/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8446 - mae: 0.7951 - val_loss: 1.0097 - val_mae: 0.8408\n",
      "Epoch 12/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8576 - mae: 0.7998 - val_loss: 1.0309 - val_mae: 0.8457\n",
      "Epoch 13/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8283 - mae: 0.7847 - val_loss: 1.0199 - val_mae: 0.8425\n",
      "Epoch 14/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8014 - mae: 0.7636 - val_loss: 1.0243 - val_mae: 0.8438\n",
      "Epoch 15/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8134 - mae: 0.7749 - val_loss: 1.0344 - val_mae: 0.8520\n",
      "Epoch 16/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8061 - mae: 0.7754 - val_loss: 1.0253 - val_mae: 0.8412\n",
      "Epoch 17/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8048 - mae: 0.7703 - val_loss: 1.0359 - val_mae: 0.8431\n",
      "Epoch 18/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7655 - mae: 0.7454 - val_loss: 1.0400 - val_mae: 0.8504\n",
      "Epoch 19/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.7513 - mae: 0.7424 - val_loss: 1.0569 - val_mae: 0.8580\n",
      "Epoch 20/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7342 - mae: 0.7364 - val_loss: 1.0566 - val_mae: 0.8495\n",
      "Epoch 21/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7346 - mae: 0.7326 - val_loss: 1.0459 - val_mae: 0.8483\n",
      "Epoch 22/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7127 - mae: 0.7203 - val_loss: 1.0679 - val_mae: 0.8570\n",
      "Epoch 23/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6955 - mae: 0.7077 - val_loss: 1.0661 - val_mae: 0.8539\n",
      "Epoch 24/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6763 - mae: 0.7001 - val_loss: 1.0811 - val_mae: 0.8632\n",
      "Epoch 25/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6901 - mae: 0.7110 - val_loss: 1.0812 - val_mae: 0.8566\n",
      "Epoch 26/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6710 - mae: 0.6953 - val_loss: 1.0887 - val_mae: 0.8629\n",
      "Epoch 27/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6368 - mae: 0.6773 - val_loss: 1.0925 - val_mae: 0.8659\n",
      "Epoch 28/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6575 - mae: 0.6900 - val_loss: 1.1123 - val_mae: 0.8782\n",
      "Epoch 29/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6292 - mae: 0.6645 - val_loss: 1.1093 - val_mae: 0.8742\n",
      "Epoch 30/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6582 - mae: 0.6808 - val_loss: 1.1102 - val_mae: 0.8763\n",
      "Epoch 31/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6215 - mae: 0.6555 - val_loss: 1.1386 - val_mae: 0.8800\n",
      "Epoch 32/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6149 - mae: 0.6585 - val_loss: 1.1300 - val_mae: 0.8751\n",
      "Epoch 33/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5859 - mae: 0.6395 - val_loss: 1.1303 - val_mae: 0.8841\n",
      "Epoch 34/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5946 - mae: 0.6522 - val_loss: 1.1444 - val_mae: 0.8897\n",
      "Epoch 35/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5803 - mae: 0.6436 - val_loss: 1.1405 - val_mae: 0.8815\n",
      "Epoch 36/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5922 - mae: 0.6498 - val_loss: 1.1702 - val_mae: 0.8923\n",
      "Epoch 37/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5499 - mae: 0.6151 - val_loss: 1.1566 - val_mae: 0.8882\n",
      "Epoch 38/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5424 - mae: 0.6184 - val_loss: 1.1794 - val_mae: 0.8951\n",
      "Epoch 39/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5522 - mae: 0.6222 - val_loss: 1.1765 - val_mae: 0.9081\n",
      "Epoch 40/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5181 - mae: 0.5916 - val_loss: 1.1811 - val_mae: 0.9050\n",
      "Epoch 41/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5058 - mae: 0.5901 - val_loss: 1.1882 - val_mae: 0.8984\n",
      "Epoch 42/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4912 - mae: 0.5800 - val_loss: 1.2020 - val_mae: 0.9098\n",
      "Epoch 43/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5159 - mae: 0.5988 - val_loss: 1.2323 - val_mae: 0.9198\n",
      "Epoch 44/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4892 - mae: 0.5757 - val_loss: 1.2320 - val_mae: 0.9230\n",
      "Epoch 45/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4568 - mae: 0.5531 - val_loss: 1.2187 - val_mae: 0.9066\n",
      "Epoch 46/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4778 - mae: 0.5625 - val_loss: 1.2765 - val_mae: 0.9293\n",
      "Epoch 47/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4980 - mae: 0.5840 - val_loss: 1.2420 - val_mae: 0.9269\n",
      "Epoch 48/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4614 - mae: 0.5614 - val_loss: 1.2652 - val_mae: 0.9331\n",
      "Epoch 49/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4503 - mae: 0.5505 - val_loss: 1.2645 - val_mae: 0.9312\n",
      "Epoch 50/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4454 - mae: 0.5472 - val_loss: 1.2782 - val_mae: 0.9357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fa8c05f09e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(\"/home/hanyan/dev/DS3001_project/DATA/sleep_cycle_productivity.csv\") # !!change this to your path!!\n",
    "\n",
    "# feature engineering \n",
    "# 1. sleep consistency = std dev of total sleep hours per person\n",
    "sleep_consistency = df.groupby('Person_ID')['Total Sleep Hours'].std().rename(\"Sleep Consistency\")\n",
    "df = df.merge(sleep_consistency, on=\"Person_ID\")\n",
    "\n",
    "# 2. sleep efficiency = total sleep hours / (sleep end - sleep start)\n",
    "df[\"Sleep Duration Window\"] = (df[\"Sleep End Time\"] - df[\"Sleep Start Time\"]) % 24\n",
    "df[\"Sleep Efficiency\"] = df[\"Total Sleep Hours\"] / df[\"Sleep Duration Window\"]\n",
    "\n",
    "# 3. screen ratio = screen time before bed / sleep duration window\n",
    "df[\"Evening Screen Ratio\"] = df[\"Screen Time Before Bed (mins)\"] / (df[\"Sleep Duration Window\"] * 60)\n",
    "\n",
    "# drop intermediate columns\n",
    "df = df.drop(columns=[\"Sleep Duration Window\"])\n",
    "\n",
    "# one-hot encoding categorical variables\n",
    "categorical_features = [\"Gender\"]\n",
    "numerical_features = df.select_dtypes(include=[\"number\"]).drop(columns=[\"Person_ID\"]).columns.tolist()\n",
    "\n",
    "# handle multicollinearity: remove highly correlated features \n",
    "corr_matrix = df[numerical_features].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.8)]\n",
    "df_reduced = df.drop(columns=to_drop)\n",
    "\n",
    "# standardize numeric features for kNN/ANN \n",
    "final_numeric = df_reduced.select_dtypes(include=[\"number\"]).drop(columns=[\"Person_ID\"]).columns\n",
    "scaler = StandardScaler()\n",
    "df_scaled = df_reduced.copy()\n",
    "df_scaled[final_numeric] = scaler.fit_transform(df_reduced[final_numeric])\n",
    "\n",
    "df_scaled.head()\n",
    "\n",
    "# drop ID, Date, and categorical columns\n",
    "exclude_cols = [\"Person_ID\", \"Date\"]\n",
    "X = df_scaled.drop(columns=exclude_cols + [\"Productivity Score\"], errors='ignore')\n",
    "y = df_scaled[\"Productivity Score\"]\n",
    "\n",
    "# remove any object/datetime columns just in case\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "# remove rows with missing values\n",
    "Xy = pd.concat([X, y], axis=1).dropna()\n",
    "X = Xy.drop(columns=[\"Productivity Score\"])\n",
    "y = Xy[\"Productivity Score\"]\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "# lasso for feature selection\n",
    "lasso = LassoCV(cv=5, random_state = 50)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_selected_features = X.columns[(lasso.coef_ != 0)].tolist()\n",
    "\n",
    "# pca for 95% variance\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "lasso_selected_features, X_pca.shape\n",
    "\n",
    "# dataframe of principal components\n",
    "pca_columns = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "df_pca = pd.DataFrame(X_pca, columns=pca_columns)\n",
    "df_pca[\"Productivity Score\"] = y.values  # add target back in\n",
    "\n",
    "df_pca.head()\n",
    "\n",
    "# split pca data\n",
    "X = df_pca.drop(columns=[\"Productivity Score\"])\n",
    "y = df_pca[\"Productivity Score\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "# basic ANN\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # regression output\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda4830",
   "metadata": {},
   "source": [
    "The model provides a coarse estimate of productivity, but its predictive power is limited. further progress likely requires richer or more subjective data.\n",
    "still, the pipeline demonstrates an end-to-end architecture from raw behavioral data to interpretable prediction.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
